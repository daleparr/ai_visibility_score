# üö® DATABASE EMERGENCY FIX GUIDE

## **CRITICAL ISSUE SUMMARY**

The ADI system is currently **losing evaluation data** due to database schema mismatches:

- **Missing Tables**: `crawl_site_signals`, `website_snapshots`
- **Missing Columns**: 8 columns in `evaluation_results` table
- **Impact**: Critical crawl data and evaluation results are being silently dropped
- **Urgency**: HIGH - Every evaluation is losing valuable data

## **üöÄ RAPID DEPLOYMENT SOLUTION**

### **Option 1: Automated PowerShell Deployment (Recommended for Windows)**

```powershell
# Set your database URL
$env:DATABASE_URL = "your_neondb_connection_string"

# Run the emergency fix
.\scripts\deploy_emergency_schema_fix.ps1
```

### **Option 2: Manual SQL Deployment**

```bash
# Connect to your database and run:
psql "$DATABASE_URL" -f drizzle/emergency_schema_fix.sql
```

### **Option 3: NeonDB Console Deployment**

1. Open NeonDB Console
2. Go to SQL Editor
3. Copy contents of `drizzle/emergency_schema_fix.sql`
4. Execute the script

## **üìä WHAT THE FIX DOES**

### **Creates Missing Tables:**

1. **`production.crawl_site_signals`**
   - Stores website performance metrics
   - Load times, mobile-friendliness, HTTPS status
   - Currently: Data is lost (try-catch skips writes)
   - After fix: All crawl signals saved properly

2. **`production.website_snapshots`**
   - Stores HTML content and screenshots
   - Critical for probe analysis and debugging
   - Currently: Data is lost (try-catch skips writes)
   - After fix: All website content preserved

### **Adds Missing Columns to `evaluation_results`:**

- `has_schema` (BOOLEAN)
- `schema_type` (VARCHAR)
- `schema_errors` (JSONB)
- `has_meta_description` (BOOLEAN)
- `has_title` (BOOLEAN)
- `has_h1` (BOOLEAN)
- `is_mobile_friendly` (BOOLEAN)
- `load_time_ms` (INTEGER)

### **Prepares for Enhanced Features:**

3. **`production.probe_results`**
   - Ready for enhanced probe prompts
   - Stores reasoning chains and confidence scores
   - Multi-model validation results

4. **`production.hybrid_crawl_data`**
   - Stores Hybrid Crawl Agent results
   - Brave API, Google CSE, domain analysis data
   - Quality scores and execution metrics

## **üîç VERIFICATION PROCESS**

The fix includes a built-in verification function:

```sql
SELECT * FROM production.verify_schema_integrity();
```

**Expected Output:**
```
table_name          | column_name    | status
--------------------|----------------|--------
crawl_site_signals  | table_exists   | OK
website_snapshots   | table_exists   | OK
evaluation_results  | has_schema     | OK
evaluation_results  | load_time_ms   | OK
probe_results       | table_exists   | OK
hybrid_crawl_data   | table_exists   | OK
```

## **‚ö†Ô∏è CURRENT DATA LOSS EVIDENCE**

From the logs, we can see the system is currently failing:

```
[DB_WRITE_SKIP] Failed to save crawl_site_signals (table may not exist)
[DB_WRITE_SKIP] Failed to save website_snapshots (table may not exist)
NeonDbError: column "has_schema" of relation "evaluation_results" does not exist
```

**This means:**
- ‚ùå Crawl performance data: LOST
- ‚ùå Website HTML content: LOST  
- ‚ùå Schema analysis results: LOST
- ‚ùå Mobile-friendliness data: LOST
- ‚ùå Load time metrics: LOST

## **‚úÖ POST-FIX BENEFITS**

After deploying the fix:

1. **Data Preservation**: All evaluation data will be saved
2. **Enhanced Debugging**: Website snapshots available for analysis
3. **Performance Metrics**: Crawl signals tracked properly
4. **Probe Readiness**: Tables ready for enhanced probe prompts
5. **Hybrid Crawl Support**: Full data storage for new crawl agent

## **üöÄ DEPLOYMENT STEPS**

### **Step 1: Backup (Optional but Recommended)**
```bash
# The script automatically creates a backup
# Manual backup:
pg_dump "$DATABASE_URL" > backup_$(date +%Y%m%d).sql
```

### **Step 2: Deploy the Fix**
```powershell
# Windows PowerShell
.\scripts\deploy_emergency_schema_fix.ps1 -DatabaseUrl "your_connection_string"
```

### **Step 3: Verify Success**
```sql
SELECT * FROM production.verify_schema_integrity();
```

### **Step 4: Test Evaluation**
Run a test evaluation and verify no more "table does not exist" errors in logs.

### **Step 5: Monitor**
Watch application logs to confirm data is being saved:
```
[DB_WRITE] Saved crawl_site_signals for evaluation_id
[DB_WRITE] Saved website_snapshots for evaluation_id
‚úÖ [DB] Dimension score created (ORM): evaluation_results
```

## **üéØ IMPACT ON ENHANCED PROBES**

The enhanced probe prompts will generate much richer data:

**Before Fix:**
- Basic probe results stored in simple format
- Limited reasoning data
- No multi-source validation

**After Fix:**
- Full reasoning chains stored in `probe_results.reasoning_chain`
- Multi-model confidence scores tracked
- Enhanced probe outputs preserved for analysis
- Hybrid Crawl Agent data available for probe context

## **‚è∞ DEPLOYMENT TIMELINE**

- **Preparation**: 2 minutes (review script)
- **Execution**: 30 seconds (run script)
- **Verification**: 1 minute (check results)
- **Testing**: 2 minutes (run test evaluation)
- **Total**: ~5 minutes to complete fix

## **üÜò ROLLBACK PLAN**

If issues occur (unlikely):

1. **Restore from backup** (if created)
2. **Drop new tables** (they won't break existing functionality)
3. **Remove new columns** (application handles missing columns gracefully)

The fix is designed to be **additive only** - it doesn't modify existing data.

## **üìû SUPPORT**

If deployment fails:

1. Check DATABASE_URL is correct
2. Verify psql is installed and accessible
3. Ensure database user has CREATE TABLE permissions
4. Check network connectivity to NeonDB

**The system is currently losing critical data with every evaluation. This fix should be deployed immediately to prevent further data loss.**
