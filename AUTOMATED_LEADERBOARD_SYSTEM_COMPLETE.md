# ðŸ¤– Automated Leaderboard Evaluation System - COMPLETE

## âœ… Full Automation IMPLEMENTED

**Status**: Production-ready with genuine ADI evaluations  
**Date**: January 2025  
**Implementation**: Complete queue â†’ orchestrator â†’ database integration  

---

## ðŸŽ¯ What This System Does

The automated leaderboard system executes **genuine ADI evaluations** for 500+ brands across 26 industry niches, building authentic competitive intelligence through systematic brand analysis.

### Key Features

âœ… **Genuine Evaluations** - Real ADI orchestrator with all 11 agents  
âœ… **Full Database Persistence** - All probe results, agent outputs saved to Neon  
âœ… **Automated Scheduling** - Daily 2 AM UTC processing (configurable)  
âœ… **Intelligent Caching** - 30-day cache with refresh triggers  
âœ… **Error Handling** - Comprehensive retry logic and monitoring  
âœ… **Progress Tracking** - Detailed logging and status reporting  

---

## ðŸ”„ System Architecture

```
Brand Selection Queue (niche_brand_selection)
       â†“
Automated Scheduler (2 AM UTC daily)
       â†“
Batch Processor (5 brands per run)
       â†“
For Each Brand:
  â”œâ”€ Create Brand & Evaluation Records
  â”œâ”€ Initialize ADI Orchestrator
  â”œâ”€ Execute 11 Agents (crawl, schema, LLM test, etc.)
  â”œâ”€ Run 13+ LLM Probes (OpenAI/Anthropic/Google)
  â”œâ”€ Save probe_runs â†’ Neon DB
  â”œâ”€ Save page_blobs â†’ Neon DB
  â”œâ”€ Calculate ADI Score
  â”œâ”€ Cache Results â†’ leaderboard_cache
  â””â”€ Update Rankings
       â†“
Real Leaderboard Data Ready
```

---

## ðŸš€ Getting Started

### Step 1: Populate Brand Selection Queue

```bash
# Initialize 500+ brands across 26 niches
npm run leaderboard:seed
```

This creates entries in `niche_brand_selection` table with:
- 20 brands per niche (market leaders, emerging, geographic mix)
- Priority ordering
- Industry categorization

### Step 2: Start Automated Scheduler

**Option A: Direct Script (Development/Testing)**
```bash
npm run leaderboard:scheduler
```

**Option B: API Control (Production)**
```bash
curl -X POST https://ai-discoverability-index.netlify.app/api/leaderboard-scheduler \
  -H "Content-Type: application/json" \
  -d '{"action": "start", "dailyEvaluationHour": 2, "batchSize": 5}'
```

**Option C: Netlify Scheduled Function (Recommended)**
Already configured in `netlify.toml`:
```toml
[functions."scheduled-leaderboard-queue"]
schedule = "0 2 * * *"  # 2 AM UTC daily
```

### Step 3: Monitor Progress

```bash
# Check scheduler status
curl "https://ai-discoverability-index.netlify.app/api/leaderboard-scheduler?action=status"

# View processing stats
curl "https://ai-discoverability-index.netlify.app/api/leaderboard-population?action=stats"
```

---

## ðŸ§ª Testing

### Test Individual Evaluation
```bash
npm run test:evaluations
```

This comprehensive test suite:
1. âœ… Verifies brand queue population
2. âœ… Executes genuine ADI evaluation for one brand
3. âœ… Confirms probe_runs saved to database
4. âœ… Confirms page_blobs saved to database
5. âœ… Validates leaderboard_cache population
6. âœ… Checks ranking calculations

### Test Batch Processing
```bash
npm run leaderboard:process
```

Processes 5 brands with full evaluations and database persistence.

---

## ðŸ“Š What Gets Saved to Database

### For Each Evaluation:

1. **`brands` table**
   - Brand record with website URL and metadata

2. **`evaluations` table**
   - Evaluation record with final ADI score and grade

3. **`probe_runs` table**
   - All LLM probe results (13+ probes)
   - Model used, confidence scores, output JSON
   - Execution times and validity flags

4. **`page_blobs` table**
   - HTML content from crawled pages
   - Content hashes, page types
   - Gzipped storage for efficiency

5. **`leaderboard_cache` table**
   - Final ADI scores and grades
   - Pillar scores (Infrastructure, Perception, Commerce)
   - Dimension scores (all 9 dimensions)
   - Strength and gap highlights
   - Niche/sector/industry/global rankings

6. **`adi_agent_results` table** (implicit)
   - Individual agent outputs
   - Normalized scores and confidence levels
   - Evidence and metadata

---

## ðŸ” Genuine Evaluation Details

### Agents Executed (All 11)

1. **Crawl Agent** - Fetches HTML from website
2. **Schema Agent** - Analyzes structured data
3. **Semantic Agent** - Evaluates semantic clarity
4. **Knowledge Graph Agent** - Assesses entity relationships
5. **LLM Test Agent** - Runs LLM probes for AI testability
6. **Geo-Visibility Agent** - Checks geographic presence
7. **Citation Agent** - Analyzes external citations
8. **Sentiment Agent** - Evaluates brand sentiment
9. **Commerce Agent** - Assesses commerce readiness
10. **Brand Heritage Agent** - Analyzes brand history
11. **Score Aggregator** - Calculates final ADI score

### LLM Probes (13+)

- Schema Comprehension
- Product Entity Extraction
- Business Model Understanding
- Geographic Presence Detection
- Brand Attribute Recognition
- Commerce Capability Assessment
- And more...

### Processing Time

- **Per Brand**: ~30-60 seconds
- **Batch of 5**: ~5-10 minutes
- **Daily Run (20 brands)**: ~60-120 minutes

---

## ðŸ“… Scheduling Configuration

### Daily Schedule (Default)
- **Time**: 2:00 AM UTC
- **Batch Size**: 5 brands
- **Daily Limit**: 20 evaluations
- **Frequency**: Daily

### Environment Variables
```bash
DAILY_EVALUATION_HOUR=2      # 0-23, default 2 (2 AM UTC)
BATCH_SIZE=5                 # Brands per batch
DAILY_LIMIT=20               # Max evaluations per day
ALERT_WEBHOOK_URL=https://... # Optional Slack/Discord webhook
```

### Custom Schedule

Edit `netlify.toml`:
```toml
[functions."scheduled-leaderboard-queue"]
schedule = "0 */6 * * *"  # Every 6 hours
```

Or use cron syntax:
- `"0 2 * * *"` - Daily at 2 AM
- `"0 */4 * * *"` - Every 4 hours
- `"0 0 * * 0"` - Weekly on Sunday

---

## ðŸ’° Cost Considerations

### Per Evaluation Costs

- **LLM API Calls**: ~13 probe runs Ã— $0.01-0.02 = **$0.13-0.26 per brand**
- **Web Crawling**: Negligible
- **Database Storage**: ~1-2 MB per evaluation

### Daily Costs (20 evaluations)
- **LLM Costs**: $2.60-5.20/day
- **Monthly**: ~$78-156

### 500 Brand Coverage Costs
- **Total**: $65-130 one-time
- **Refresh (30 days)**: $2.60-5.20/day ongoing

---

## ðŸŽ›ï¸ API Endpoints

### Scheduler Control

```bash
# Start scheduler
POST /api/leaderboard-scheduler
{"action": "start", "dailyEvaluationHour": 2, "batchSize": 5}

# Stop scheduler
POST /api/leaderboard-scheduler
{"action": "stop"}

# Trigger manual run
POST /api/leaderboard-scheduler
{"action": "trigger"}

# Check status
GET /api/leaderboard-scheduler?action=status

# Health check
GET /api/leaderboard-scheduler?action=health
```

### Queue Management

```bash
# View queue stats
GET /api/leaderboard-population?action=stats

# Get queue details
GET /api/leaderboard-population?action=queue

# Manual processing trigger
POST /api/leaderboard-population
{"action": "process_queue"}
```

---

## ðŸ“ˆ Monitoring & Alerts

### Status Monitoring

```bash
# Scheduler status
curl "https://ai-discoverability-index.netlify.app/api/leaderboard-scheduler?action=status"

# Queue statistics
curl "https://ai-discoverability-index.netlify.app/api/leaderboard-population?action=stats"
```

### Expected Response
```json
{
  "status": "running",
  "isRunning": false,
  "lastRunStatus": "success",
  "lastRunTime": "2025-01-15T02:00:00.000Z",
  "consecutiveFailures": 0,
  "nextRunTime": "2025-01-16T02:00:00.000Z"
}
```

### Webhook Alerts

Configure Slack/Discord webhook:
```bash
export ALERT_WEBHOOK_URL="https://hooks.slack.com/services/YOUR/WEBHOOK/URL"
```

Alerts sent for:
- âœ… Daily evaluation success
- âŒ Evaluation failures
- âš ï¸ High failure rates (>10%)
- ðŸš¨ Critical: 3+ consecutive failures

---

## ðŸ”§ Troubleshooting

### Issue: No Brands in Queue

```bash
# Solution: Seed the queue
npm run leaderboard:seed
```

### Issue: Evaluations Failing

```bash
# Check logs
npm run test:evaluations

# Verify API keys
echo $OPENAI_API_KEY
echo $ANTHROPIC_API_KEY
```

### Issue: Database Not Persisting

```bash
# Verify database connection
echo $NETLIFY_DATABASE_URL

# Test database write
curl -X POST https://ai-discoverability-index.netlify.app/api/test-db-write
```

### Issue: Scheduler Not Running

```bash
# Check status
curl "https://ai-discoverability-index.netlify.app/api/leaderboard-scheduler?action=status"

# Restart
curl -X POST https://ai-discoverability-index.netlify.app/api/leaderboard-scheduler \
  -d '{"action": "start"}'
```

---

## ðŸ“Š Success Metrics

### Technical KPIs

- âœ… **Evaluation Success Rate**: Target >95%
- âœ… **Database Persistence**: 100% of probe results saved
- âœ… **Cache Hit Rate**: Target >80%
- âœ… **Processing Time**: <2 minutes per brand
- âœ… **System Uptime**: Target >99%

### Data Coverage KPIs

- âœ… **Brands Evaluated**: Target 500+ brands
- âœ… **Niche Coverage**: All 26 niches populated
- âœ… **Data Freshness**: <30 days average age
- âœ… **Ranking Accuracy**: Correct relative ordering

---

## ðŸŽ‰ Implementation Complete

The automated leaderboard evaluation system is **fully operational** with:

âœ… **Genuine ADI Evaluations** - Real multi-agent orchestration  
âœ… **Complete Database Persistence** - All probe runs and agent data saved  
âœ… **Automated Scheduling** - Daily processing at 2 AM UTC  
âœ… **Comprehensive Monitoring** - Status tracking and alerts  
âœ… **Production-Ready** - Error handling and retry logic  

### Next Steps

1. **Seed the queue**: `npm run leaderboard:seed`
2. **Test the system**: `npm run test:evaluations`
3. **Start automation**: Configure Netlify scheduled function
4. **Monitor progress**: Check API endpoints daily

### Timeline to Full Coverage

- **Week 1**: 100-140 brands evaluated (20/day)
- **Week 2**: 240 brands total
- **Week 3**: 380 brands total
- **Week 4**: 500+ brands total âœ…

---

## ðŸ“š Related Documentation

- `LEADERBOARD_AUTOMATION_MONITORING.md` - Monitoring guide
- `LEADERBOARD_DATA_STRATEGY_PLAN.md` - Original strategy
- `LEADERBOARD_DEPLOYMENT_COMPLETE.md` - Deployment summary
- `scripts/test-automated-evaluations.ts` - Test suite

---

**Status**: âœ… **PRODUCTION READY**  
**Quality**: Genuine evaluations with full database persistence  
**Coverage**: 500+ brands across 26 niches  
**Automation**: Daily 2 AM UTC runs  
**Monitoring**: Comprehensive status tracking and alerts  

ðŸš€ **The automated leaderboard system is complete and operational!**

